### Cassandra Basics
- Cassandra is open-source, distributed NoSQL DB
- Implements partitioned wide-column storage model
- Wide-column DB: names and format of columns can vary across rows even within same table

#### Data Model

- **Keyspace** - data containers (analogous to 'databases' in SQL)
	- Contains many tables
	- Owns configuration information (such as configured replication strategy)
	- Owns user-defined-types (UDTs)
- **Table** - container for data in the form of rows
- **Row** - container for data represented by a primary key and contains columns
- **Column** - represented by a name, type, value
	- Since Cassandra is wide-column database, specified columns can vary per row in table
	- Columns have timestamp metadata associated with it
		- When column has write conflict between replicas, resolved via "last write wins"
	- Support many types, including UDTs and JSON values -> flexible for flat and nested data

#### Primary Key
- Each row is represented by unique primary key
	- Consists of one of more partition keys and may include clustering keys
- **Partition Key**: One or more columns used to determine what partition the row is in
- **Clustering Key**: Zero or more columns used to determine the sorted order of rows in table

### Key Concepts
#### Partitioning
- Cassandra achieves horizontal scalability by partitioning data via consistent hashing
- Traditional hashing: node determine by `hash(value) % num_nodes`
	- Problems:
	1. If node is added or removed, lots of value would be assigned new nodes so huge amounts of data moved
	2. If hashing scheme is bad, many values might get hashed to same node -> uneven load between nodes
- **Consistent hashing** hashes a value to a range of integers visualized on a ring
	- Prevents excess re-mapping of values 
		- If node enters, it re-maps some values from node clockwise ahead of it
		- If node exits, values from this node are moved to node clockwise ahead of it
- Cassandra addresses uneven load issue by mapping multiple nodes on ring (virtual nodes `vnodes`) to physical nodes
	- Better distributes load instead of 1 to 1 mapping of range -> node, 
	- Physical nodes might have more resources, so they are responsible for more vnodes

#### Replication
- Configurations are specified in keyspaces
- **NetworkTopologyStrategy** - for prod, is data center/rack aware
	- Main goal is to establish enough physical separation of replicas in case of real world outage
- **SimpleStrategy** - for simple deployments and testing
	- Cassandra scans clockwise from the vnode corresponding to hashed value
	- For example, if Cassandra wants to replicate data to 3 nodes, it hashes a value to a node and scans clockwise to find 2 additional vnodes (that are not on same physical node as #1) for replicas

#### Consistency
- Subject to CAP Theorem but Cassandra gives users flexibility over consistency settings for reads / writes to "tune" consistency vs availability trade-off
- Offers "consistency levels": required node response numbers for read/write to succeed
	- Eg `ONE` is single replica needs to respond, `ALL` is all replicas must response
	- `QUORUM` is majority (n/2 + 1) of replicas respond
		- Guarantees that writes are visible to reads because at least 1 node overlaps in read and write
			- eg. in a 3 node system, 2 nodes can write and 2 nodes can read, therefore 1 node can read AND write)
- Overall aim: eventual consistency
- Callout: Does not offer ACID guarantees aka transaction support
	- Only supports atomic and isolated writes at row level in a partition

#### Query Routing
- Any node can be query "coordinator"
- All nodes in Cassandra know about other alive nodes in cluster
	- Cluster info is shared via "gossip" protocol
- All nodes can determine where data lives in cluster via performing consistent hashing calculations and by knowing replication strategy / consistency level configured

#### Storage Model 
- Relational DB is "entity-relationship driven": you have one copy of each entity (data is "normalized) and you manage relationship between entities via foreign keys and JOIN-tables
- Cassandra is "query-driven"
	- Queries are efficient because it doesn't support JOINs and services single table queries
- Main considerations of what data is needed in each table:
	- **Partition Key**: What data determines what partition data is on
	- **Partition Size**: How big a partition is in most extreme case; Can partitions grow indefinitely
	- **Clustering Key**: How the data should be sorted
	- **Data Denormalization**: Whether certain data needs to be denormalized to support app's queries

#### Example: Discord Messages

First iteration of message data table:
```
CREATE TABLE messages (
  channel_id bigint,
  message_id bigint,
  author_id bigint,
  content text,
  PRIMARY KEY (channel_id, message_id)
) WITH CLUSTERING ORDER BY (message_id DESC);
```
- Partition key `channel_id` ensures a single partition is responsible for service query instead of querying across several nodes ("scatter-gather") which is slow/resource-intensive 
- Users usually want to query recent data first, so sort in reverse chronological order makes sense
- Note: `message_id` used instead of a timestamp `created_at` because a chronologically sortable UUID will never result in primary key collision while timestamp even with ms granularity may have collision
	- IDs can be generated using techinques likes:
	1. Auto-incrementing counters per partition
	2. Timestamp-based UUIDs (UUID v1)
	3. Snowflake IDs
	4. ULID
- Issue: Busy discord channels would have large partitions -> performance problems
- Issue: Discord channels can perpetually grow in size with message activity -> performance problems if channel lived long enough

Second iteration:
```
CREATE TABLE messages (
  channel_id bigint,
  bucket int,
  message_id bigint,
  author_id bigint,
  content text,
  PRIMARY KEY ((channel_id, bucket), message_id)
) WITH CLUSTERING ORDER BY (message_id DESC);
```
- Introduced concept of `bucket` representing 10 days of data
	- Fixes issue of monotonically growing partitions because new bucket made every 10d
	- Could query a single partition to service writes most of time except in edge cases:
		1. New bucket created on 10 day breakpoint
		2. For inactive discords (minority of queries)

#### Example: Ticketmaster

First iteration of tickets table to support a ticket browsing UI:
```
CREATE TABLE tickets (
  event_id bigint,
  seat_id bigint,
  price bigint,
  -- seat_id is added as a clustering key to ensure primary key uniqueness; order
  -- doesn't matter for the app access patterns
  PRIMARY KEY (event_id, seat_id)
);
```
- Partition key of `event_id` ensures a single partition is responsible for service query
- Issues: For large events with 10k+ tickets, database needs to perform work to summarize information based on user's query (price total, ticket total)
- Issues: For popular events, many queries -> performance problems

Second iteration of tickets table based on UI/UX: when user clicks on section of interest, UI shows individual seats and ticket information:
```
CREATE TABLE tickets (
  event_id bigint,
  section_id bigint,
  seat_id bigint,
  price bigint,
  PRIMARY KEY ((event_id, section_id), seat_id)
);
```
- Adding section_id to partition key distributes event over several nodes

To show high-level ticket data for entire event, we make separate table `event_sections`
```
CREATE TABLE event_sections (
  event_id bigint,
  section_id bigint,
  num_tickets bigint,
  price_floor bigint,
  -- section_id is added as a clustering key to ensure primary key uniqueness; order
  -- doesn't matter for the app access patterns
  PRIMARY KEY (event_id, section_id)
);
```
- "Denormalize data" - instead of database doing aggregation on table to service app, denormalize ticket numbers and price_floor to make access pattern for app efficient

#### Advanced Features
1. Storage Attached Indexes (SAI)
	- Global secondary indexes on columns: flexible querying of data instead of traditional querying based off partition key
		- Less performant but avoids excess denormalizing of data for less frequent query patterns
2. Materialized Views 
	- Cassandra can denormalize data automatically for you
3. Search Indexing
	- Use plugins to wire Cassandra up to distributed search engine such as ElasticSearch or Apache Solr

#### Cassandra in an Interview
When to use?
- Systems that prioritize availability over consistency
- Systems that have high scalability needs
- Especially good for high write systems due to its write-optimized storage layer based on LSM tree indexing
- Wide-column design good for:
	- Flexible schemas
	- Schemas that involve many columns that might be sparse
- When you have several clear access patterns for application that schema can revolve around

Limitations:
- Not good for strong consistency since it biases towards availability
- Not good for systems that need advanced query patterns: multi-table JOINs, adhoc aggregations, etc