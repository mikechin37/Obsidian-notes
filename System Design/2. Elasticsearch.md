#### Basics
Documents
- Units of data you're search (think of JSON object)
	- associated with unique ID and set of fields
Indices
- Collection of documents  (think of database table)
Mappings and Fields
- Mapping: schema of index
#### Basic Use
- simple REST API to perform operations to create index, store data, and perform search
- requests to add documents returns a unique document ID
	- `_version` field is special field that Elasticsearch uses to ensure atomic updating
		- **optimistic concurrency control**: use version so only update document if version matches
Search
- Elasticsearch query syntax is similar to SQL but is JSON based
Sort
- Basic Sorting
	- use `sort` parameter in search query for single or multiple fields (eg price)
- Relevance-Based Sorting
	- default scoring based on **TF-IDF** 
	- TF-IDF (Term Frequency-Inverse Document Frequency)
		- Term Frequency
			- how often term appears in a document
		- Inverse Document Frequency
			- how rare or important a term is across all documents ("the", "and" get low scores)
Pagination and Cursors
- From/Size Pagination
	- Simplest method where you specify starting starting index of results `from` and number of results to return `size`
		- Drawback: inefficient for deep pagination (> 10k results) due to overhead of sorting and fetching all documents
- Search After
	- Uses sort values of last result as starting point for next page to progressively restrict search set
		- Implement with `search_after` parameter for eg. timestamp, doc_id
	- Advs:
	1. Don't miss documents added in subsequent pages (even if new documents are added between requests)
	2. Don't get duplicate results across pages
	- Disadvs:
	1. Requires maintaining state on client side (remembering sort values of last document)
	2. Doesn't allow random access to pages - must move forward through results
	3. Risk missing documents in prior pages if underlying data is updated or deleted
- Cursors
	- Provide stateful way to paginate through search results so documents dont shift underneath
	- Use `point in time (PIT) API` in conjunction with searc_after for cursor_based pagination
		- Creates stable snapshot of data so subsequent searches will return same data

#### Cluster Architecture

Node Types
- **Master Node**: admin that perform cluster-level operations like add/remove nodes, create/delete indices
- **Data Node**: where data is stored, many of these
	- House indices made up of shards and replicas
		- Inside shards are Lucene indexes made of Lucene segments
- **Coordinating Node**: the front end - coordinates search requests across cluster - receives search request and sends to appropriate nodes
- **Ingest Node** : responsible for data ingestion - transforms data and prepares it for indexing
- **Machine Learning Node** : ML tasks
Lucene
- the low-level search library
- Lucene indexes
	- Made of **segments** : immutable containers of indexed data 
- Batches writes and construct segments
	- When we insert document, don't immediately store it in index but add it to segment
	- When we have a batch of documents, we finally construct segment and flush to disk
- Deletions
	- Don't actually delete documents, but use deleted identifiers to pretend document doesn't exist upon query
	- During merge operations, merged segments clean up deleted documents
- Updates
	- Soft delete old document and insert new document with updated data
	- Old document gets cleaned up on segment merge events later
- Benefits of immutable architecture
1. Improved write performance
	- New documents are quickly added to new segments without modifying existing ones
2. Efficient caching
	- Since segments are immutable, we can cache in memory or on SSD without consistency issues
3. Simplified concurrency
	- Read ops dont need to worry about data changing mid-query
4. Easier recovery
	- After crash, easier to recover from immutable segments since state is known and consistent
5. Optimized compression
	- Immutable data can be more effectively compressed to save disk space
6. Faster searches
	- Can optimize data structures/algos for search immutable structures

#### Lucene Segment Features

Inverted Index
- Copy data and cleverly arrange it as hash table
- Hash table to map unique word -> document ID 
Doc Values
- Columnar, contiguous representation of a single field for all documents across segment

#### Coordinating Nodes
Query Planners : algorithms that determine most efficient way to execute search query
Order Optimization
- Example options to search for "bill nye"
1. Generate hashset of all documents with "nye",  scan over documents that contain "bill", look for intersection, then do string search for "bill nye"
2. Generate hashset of all documents with "bill",  scan over documents that contain "nye", look for intersection, then do string search for "bill nye"
3. Load all documents with "nye" then string search for "bill nye"
4. etc etc
- Query planners add layer of statistics to choose fastest option
	- Collect stats on types of fields present, keywords that are popular, length of documents
	- Dynamically respond to data in the index

#### Using Elasticsearch
1. Bad consistency and durability -> Don't use as Database
2. Good for read-heavy not write-heavy
3. Has eventual consistency -> Results will be stale sometimes
4. Not relational database - search queries are more efficient when data is denormalized
5. If data is small (<100k documents) or doesn't change often, can simply query against primary data store
6. Commonly fails in keeping in sync with underlying data