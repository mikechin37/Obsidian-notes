
#### Basics
- in-memory, single threaded, key-value store 
- Main adv: speed
- Main disadv: durability
	- Don't get same disk-based durability guarantees like SQL DB about being written to disk in exchange for speed
Infrastructure Configuration
- Single node with high availability (HA) replica OR
- Cluster 
	- Redis client cache set of "hash slots" -> maps keeps to a specific node
		- Therefore, clients directly connect to node containing desired data
		- Nodes are aware of other nodes via gossip protocol so if request key from the wrong node, you can be redirected to correct node
	- Very basic setup - Redis expects all data for a given request to be on single node
		- Choosing how to structure keys is key to scale Redis
Performance
- Redis can handle O(100k) writes per second
- Read latency in microsecond range
#### Capabilities
- Redis as Cache
- Redis as Distributed Lock
	- Simple lock with timeout 
		- Set a key-value entry like "ticket_lock": UUID
		- When done with lock, we DEL the key so other processes make use of it
	- Why?
	1. Maintain consistency during updates
	2. Make sure multiple people aren't performing action at same time
- Redis for Leaderboards
	- Redis' sorted sets maintain list of eg. top liked posts
		- High write throughput and low read latency are good when SQL DB will struggle
- Redis for Rate Limiting
	- Examples
	1. API Rate Limiting
	2. Login Attempt Limit
	3. Spam Protection for posting
	- Fixed-window rate limiter
		- Guarantee number of requests does not exceed N over fixed window of time W
		- Increment key for our rate limiter and check response (eg. "rate_limit:user123")
		- If response is greater than N, we wait
		- Expire key after time period W
- Redis for Proximity Search
	- GEOADD and GEORADIUS commands add "location": (long, lat, member)
- Redis for Event Sourcing
	- Redis' streams are append-only logs like Kafka topics

#### Shortcomings

Hot Key Issues
- eg. Ecommerce website: surge of interest for one particular item
	- Now load on one server is much higher than rest
- Solutions
1. Add in-memory cache in our clients so they aren't making so many requests to Redis
2. Store same data in multiple keys and randomize requests so they are spread across the cluster
3. Add read replica instance and dynamically scale these with load